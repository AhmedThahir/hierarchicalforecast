{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierachical Reconciliation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from statsmodels.stats.moment_helpers import cov2corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import ExceptionExpected, test_close, test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reconcile(S: np.ndarray, P: np.ndarray, W: np.ndarray, \n",
    "               y_hat: np.ndarray, SP: np.ndarray = None):\n",
    "    if SP is None:\n",
    "        SP = S @ P\n",
    "    return np.matmul(SP, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bottom_up(S: np.ndarray,\n",
    "              y_hat: np.ndarray,\n",
    "              idx_bottom: List[int]):\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    P = np.zeros_like(S, dtype=np.float32)\n",
    "    P[idx_bottom] = S[idx_bottom]\n",
    "    P = P.T\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BottomUp:\n",
    "    \n",
    "    def reconcile(self,\n",
    "                  S: np.ndarray,\n",
    "                  y_hat: np.ndarray,\n",
    "                  idx_bottom: np.ndarray):\n",
    "        return bottom_up(S=S, y_hat=y_hat, idx_bottom=idx_bottom)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "S = np.array([\n",
    "    [1., 1., 1., 1.],\n",
    "    [1., 1., 0., 0.],\n",
    "    [0., 0., 1., 1.],\n",
    "    [0., 1., 0., 0.],\n",
    "    [1., 0., 0., 0.],\n",
    "    [0., 0., 1., 0.],\n",
    "    [0., 0., 0., 1.],\n",
    "])\n",
    "h = 10\n",
    "_y = np.array([10., 5., 4., 2., 1.])\n",
    "y_bottom = np.vstack([i * _y for i in range(1, 5)])\n",
    "y_hat_bottom_insample = np.roll(y_bottom, 1)\n",
    "y_hat_bottom_insample[:, 0] = np.nan\n",
    "y_hat_bottom = np.vstack([i * np.ones(h) for i in range(1, 5)])\n",
    "idx_bottom = [4, 3, 5, 6]\n",
    "levels = {'level1': np.array([0]),\n",
    "          'level2': np.array([1, 2]),\n",
    "          'level3': idx_bottom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "cls_bottom_up = BottomUp()\n",
    "test_eq(\n",
    "    cls_bottom_up(S=S, y_hat=S @ y_hat_bottom, idx_bottom=idx_bottom),\n",
    "    S @ y_hat_bottom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_strictly_hierarchical(S: np.ndarray, \n",
    "                             levels: Dict[str, np.ndarray]):\n",
    "    # main idea:\n",
    "    # if S represents a strictly hierarchical structure\n",
    "    # the number of paths before the bottom level\n",
    "    # should be equal to the number of nodes\n",
    "    # of the previuos level\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    # removing bottom level\n",
    "    levels_.popitem()\n",
    "    # making S categorical\n",
    "    hiers = [np.argmax(S[idx], axis=0) + 1 for _, idx in levels_.items()]\n",
    "    hiers = np.vstack(hiers)\n",
    "    paths = np.unique(hiers, axis=1).shape[1] \n",
    "    nodes = levels_.popitem()[1].size\n",
    "    return paths == nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert is_strictly_hierarchical(S, levels)\n",
    "S_non_hier = np.array([\n",
    "    [1., 1., 1., 1.], # total\n",
    "    [1., 1., 0., 0.], # city 1\n",
    "    [0., 0., 1., 1.], # city 2\n",
    "    [1., 0., 1., 0.], # transgender\n",
    "    [0., 1., 0., 1.], # no transgender\n",
    "    [1., 0., 0., 0.], #city 1 - transgender\n",
    "    [0., 1., 0., 0.], #city 1 - no transgender\n",
    "    [0., 0., 1., 0.], #city 2 - transgender\n",
    "    [0., 0., 0., 1.], #city 2 - no transgender\n",
    "])\n",
    "levels_non_hier = {\n",
    "    'Country': np.array([0]),\n",
    "    'Country/City': np.array([2, 1]),\n",
    "    'Country/Transgender': np.array([3, 4]),\n",
    "    'Country-City-Transgender': np.array([5, 6, 7, 8]),\n",
    "}\n",
    "assert not is_strictly_hierarchical(S_non_hier, levels_non_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_child_nodes(S: np.ndarray, levels: Dict[str, np.ndarray]):\n",
    "    childs = {}\n",
    "    level_names = list(levels.keys())\n",
    "    nodes = OrderedDict()\n",
    "    for i_level, level in enumerate(level_names[:-1]):\n",
    "        parent = levels[level]\n",
    "        child = np.zeros_like(S)\n",
    "        idx_child = levels[level_names[i_level+1]] \n",
    "        child[idx_child] = S[idx_child]\n",
    "        nodes_level = {}\n",
    "        for idx_parent_node in parent:\n",
    "            parent_node = S[idx_parent_node]\n",
    "            idx_node = child * parent_node.astype(bool)\n",
    "            idx_node, = np.where(idx_node.sum(axis=1) > 0)\n",
    "            nodes_level[idx_parent_node] = [idx for idx in idx_child if idx in idx_node]\n",
    "        nodes[level] = nodes_level\n",
    "    return nodes        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reconcile_fcst_proportions(S: np.ndarray, y_hat: np.ndarray,\n",
    "                                levels: Dict[str, np.ndarray],\n",
    "                                nodes: Dict[str, Dict[int, np.ndarray]],\n",
    "                                idx_top: int):\n",
    "    reconciled = np.zeros_like(y_hat)\n",
    "    reconciled[idx_top] = y_hat[idx_top]\n",
    "    level_names = list(levels.keys())\n",
    "    for i_level, level in enumerate(level_names[:-1]):\n",
    "        nodes_level = nodes[level]\n",
    "        for idx_parent, idx_childs in nodes_level.items():\n",
    "            fcst_parent = reconciled[idx_parent]\n",
    "            childs_sum = y_hat[idx_childs].sum()\n",
    "            for idx_child in idx_childs:\n",
    "                reconciled[idx_child] = y_hat[idx_child] * fcst_parent / childs_sum\n",
    "    return reconciled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def top_down(S: np.ndarray, \n",
    "             y_hat: np.ndarray,\n",
    "             y_insample: np.ndarray,\n",
    "             levels: Dict[str, np.ndarray],\n",
    "             method: str):\n",
    "    if not is_strictly_hierarchical(S, levels):\n",
    "        raise ValueError('Top down reconciliation requires strictly hierarchical structures.')\n",
    "    \n",
    "    n_hiers, n_bottom = S.shape\n",
    "    idx_top = int(S.sum(axis=1).argmax())\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    idx_bottom = levels_[list(levels_)[-1]]\n",
    "    \n",
    "    if method == 'forecast_proportions':\n",
    "        nodes = _get_child_nodes(S=S, levels=levels_)\n",
    "        reconciled = [_reconcile_fcst_proportions(S=S, y_hat=y_hat_[:, None], \n",
    "                                                  levels=levels_, \n",
    "                                                  nodes=nodes,\n",
    "                                                  idx_top=idx_top) \\\n",
    "                      for y_hat_ in y_hat.T]\n",
    "        reconciled = np.hstack(reconciled)\n",
    "        return reconciled\n",
    "    else:\n",
    "        y_top = y_insample[idx_top]\n",
    "        y_btm = y_insample[idx_bottom]\n",
    "        if method == 'average_proportions':\n",
    "            prop = np.mean(y_btm / y_top, axis=1)\n",
    "        elif method == 'proportion_averages':\n",
    "            prop = np.mean(y_btm, axis=1) / np.mean(y_top)\n",
    "        else:\n",
    "            raise Exception(f'Unknown method {method}')\n",
    "    P = np.zeros_like(S, np.float64).T #float 64 if prop is too small, happens with wiki2\n",
    "    P[:, idx_top] = prop\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TopDown:\n",
    "    \n",
    "    def __init__(self, method: str):\n",
    "        self.method = method\n",
    "    \n",
    "    def reconcile(self, \n",
    "                  S: np.ndarray, \n",
    "                  y_hat: np.ndarray,\n",
    "                  y_insample: np.ndarray,\n",
    "                  levels: Dict[str, np.ndarray],):\n",
    "        return top_down(S=S, y_hat=y_hat, \n",
    "                        y_insample=y_insample, \n",
    "                        levels=levels,\n",
    "                        method=self.method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# we are able to recover forecasts \n",
    "# from top_down in this example\n",
    "# because the time series\n",
    "# share the same proportion\n",
    "# across time\n",
    "# but it is not a general case\n",
    "for method in ['forecast_proportions', 'average_proportions', 'proportion_averages']:\n",
    "    cls_top_down = TopDown(method=method)\n",
    "    test_close(\n",
    "        cls_top_down(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom, \n",
    "            y_insample=S @ y_bottom, \n",
    "            levels=levels\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def middle_out(S: np.ndarray, \n",
    "               y_hat: np.ndarray,\n",
    "               y_insample: np.ndarray,\n",
    "               levels: Dict[str, np.ndarray],\n",
    "               level: str,\n",
    "               top_down_method: str):\n",
    "    if not is_strictly_hierarchical(S, levels):\n",
    "        raise ValueError('Middle out reconciliation requires strictly hierarchical structures.')\n",
    "    if level not in levels.keys():\n",
    "        raise ValueError('You have to provide a `level` in `levels`.')\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    reconciled = np.full_like(y_hat, fill_value=np.nan)\n",
    "    cut_nodes = levels_[level]\n",
    "    # bottom up reconciliation\n",
    "    idxs_bu = []\n",
    "    for node, idx_node in levels_.items():\n",
    "        idxs_bu.append(idx_node)\n",
    "        if node == level:\n",
    "            break\n",
    "    idxs_bu = np.hstack(idxs_bu)\n",
    "    #bottom up forecasts\n",
    "    bu = bottom_up(S=np.unique(S[idxs_bu], axis=1), \n",
    "                   y_hat=y_hat[idxs_bu], \n",
    "                   idx_bottom=np.arange(len(idxs_bu))[-len(cut_nodes):])\n",
    "    reconciled[idxs_bu] = bu\n",
    "    \n",
    "    #top down\n",
    "    child_nodes = _get_child_nodes(S, levels_)\n",
    "    # parents contains each node in the middle out level\n",
    "    # as key. The values of each node are the levels that\n",
    "    # are conected to that node.\n",
    "    parents = {node: {level: np.array([node])} for node in cut_nodes}\n",
    "    level_names = list(levels_.keys())\n",
    "    for lv, lv_child in zip(level_names[:-1], level_names[1:]):\n",
    "        # if lv is not part of the middle out to bottom\n",
    "        # structure we continue\n",
    "        if lv not in list(parents.values())[0].keys():\n",
    "            continue\n",
    "        for idx_middle_out in parents.keys():\n",
    "            idxs_parents = parents[idx_middle_out].values()\n",
    "            complete_idxs_child = []\n",
    "            for idx_parent, idxs_child in child_nodes[lv].items():\n",
    "                if any(idx_parent in val for val in idxs_parents):\n",
    "                    complete_idxs_child.append(idxs_child)\n",
    "            parents[idx_middle_out][lv_child] = np.hstack(complete_idxs_child)\n",
    " \n",
    "    for node, levels_node in parents.items():\n",
    "        idxs_node = np.hstack(list(levels_node.values()))\n",
    "        S_node = S[idxs_node]\n",
    "        S_node = S_node[:,~np.all(S_node == 0, axis=0)]\n",
    "        counter = 0\n",
    "        levels_node_ = deepcopy(levels_node)\n",
    "        for lv_name, idxs_level in levels_node_.items():\n",
    "            idxs_len = len(idxs_level)\n",
    "            levels_node_[lv_name] = np.arange(counter, idxs_len + counter)\n",
    "            counter += idxs_len\n",
    "        td = top_down(S_node, \n",
    "                      y_hat[idxs_node], \n",
    "                      y_insample[idxs_node], \n",
    "                      levels_node_, \n",
    "                      method=top_down_method)\n",
    "        reconciled[idxs_node] = td\n",
    "    return reconciled\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MiddleOut:\n",
    "    \n",
    "    def __init__(self, level: str, top_down_method: str):\n",
    "        self.level = level\n",
    "        self.top_down_method = top_down_method\n",
    "    \n",
    "    def reconcile(self, \n",
    "                  S: np.ndarray, \n",
    "                  y_hat: np.ndarray,\n",
    "                  y_insample: np.ndarray,\n",
    "                  levels: Dict[str, np.ndarray],):\n",
    "        return middle_out(S=S, y_hat=y_hat, \n",
    "                          y_insample=y_insample, \n",
    "                          levels=levels,\n",
    "                          level=self.level,\n",
    "                          top_down_method=self.top_down_method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# we are able to recover forecasts \n",
    "# from middle out in this example\n",
    "# because the time series\n",
    "# share the same proportion\n",
    "# across time\n",
    "# but it is not a general case\n",
    "for method in ['forecast_proportions', 'average_proportions', 'proportion_averages']:\n",
    "    cls_middle_out = MiddleOut(level='level2', top_down_method=method)\n",
    "    test_close(\n",
    "        cls_middle_out(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom, \n",
    "            y_insample=S @ y_bottom, \n",
    "            levels=levels\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crossprod(x):\n",
    "    return x.T @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def min_trace(S: np.ndarray, \n",
    "              y_hat: np.ndarray,\n",
    "              y_insample: np.ndarray,\n",
    "              y_hat_insample: np.ndarray,\n",
    "              method: str):\n",
    "    # shape residuals_insample (n_hiers, obs)\n",
    "    res_methods = ['wls_var', 'mint_cov', 'mint_shrink']\n",
    "    if method in res_methods and y_insample is None and y_hat_insample is None:\n",
    "        raise ValueError(f\"For methods {', '.join(res_methods)} you need to pass residuals\")\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    if method == 'ols':\n",
    "        W = np.eye(n_hiers)\n",
    "    elif method == 'wls_struct':\n",
    "        W = np.diag(S @ np.ones((n_bottom,)))\n",
    "    elif method in res_methods:\n",
    "        #we need residuals with shape (obs, n_hiers)\n",
    "        residuals = (y_insample - y_hat_insample).T\n",
    "        n, _ = residuals.shape\n",
    "        masked_res = np.ma.array(residuals, mask=np.isnan(residuals))\n",
    "        covm = np.ma.cov(masked_res, rowvar=False, allow_masked=True).data\n",
    "        if method == 'wls_var':\n",
    "            W = np.diag(np.diag(covm))\n",
    "        elif method == 'mint_cov':\n",
    "            W = covm\n",
    "        elif method == 'mint_shrink':\n",
    "            tar = np.diag(np.diag(covm))\n",
    "            corm = cov2corr(covm)\n",
    "            xs = np.divide(residuals, np.sqrt(np.diag(covm)))\n",
    "            xs = xs[~np.isnan(xs).any(axis=1), :]\n",
    "            v = (1 / (n * (n - 1))) * (crossprod(xs ** 2) - (1 / n) * (crossprod(xs) ** 2))\n",
    "            np.fill_diagonal(v, 0)\n",
    "            corapn = cov2corr(tar)\n",
    "            d = (corm - corapn) ** 2\n",
    "            lmd = v.sum() / d.sum()\n",
    "            lmd = max(min(lmd, 1), 0)\n",
    "            W = lmd * tar + (1 - lmd) * covm\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "    \n",
    "    eigenvalues, _ = np.linalg.eig(W)\n",
    "    if any(eigenvalues < 1e-8):\n",
    "        raise Exception(f'min_trace ({method}) needs covariance matrix to be positive definite.')\n",
    "        \n",
    "    R = S.T @ np.linalg.inv(W)\n",
    "    P = np.linalg.inv(R @ S) @ R\n",
    "    \n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MinTrace:\n",
    "    \n",
    "    def __init__(self, method: str):\n",
    "        self.method = method\n",
    "        \n",
    "    def reconcile(self, \n",
    "                  S: np.ndarray, \n",
    "                  y_hat: np.ndarray,\n",
    "                  y_insample: np.ndarray,\n",
    "                  y_hat_insample: np.ndarray):\n",
    "        return min_trace(S=S, y_hat=y_hat, \n",
    "                         y_insample=y_insample,\n",
    "                         y_hat_insample=y_hat_insample,\n",
    "                         method=self.method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "for method in ['ols', 'wls_struct', 'wls_var', 'mint_shrink']:\n",
    "    cls_min_trace = MinTrace(method=method)\n",
    "    test_close(\n",
    "        cls_min_trace(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom, \n",
    "            y_insample=S @ y_bottom,\n",
    "            y_hat_insample=S @ y_hat_bottom_insample\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )\n",
    "with ExceptionExpected(regex='min_trace (mint_cov)*'):\n",
    "    cls_min_trace = MinTrace(method='mint_cov')\n",
    "    cls_min_trace(\n",
    "        S=S, \n",
    "        y_hat=S @ y_hat_bottom, \n",
    "        y_insample=S @ y_bottom,\n",
    "        y_hat_insample=S @ y_hat_bottom_insample\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def lasso(X: np.ndarray, y: np.ndarray, \n",
    "          lambda_reg: float, max_iters: int = 1_000,\n",
    "          tol: float = 1e-4):\n",
    "    # lasso cyclic coordinate descent\n",
    "    n, feats = X.shape\n",
    "    norms = (X ** 2).sum(axis=0)\n",
    "    beta = np.zeros(feats, dtype=np.float32)\n",
    "    beta_changes = np.zeros(feats, dtype=np.float32)\n",
    "    residuals = y.copy()\n",
    "    \n",
    "    for it in range(max_iters):\n",
    "        for i, betai in enumerate(beta):\n",
    "            # is feature is close to zero, we \n",
    "            # continue to the next.\n",
    "            # in this case is optimal betai= 0\n",
    "            if abs(norms[i]) < 1e-8:\n",
    "                continue\n",
    "            xi = X[:, i]\n",
    "            #we calculate the normalized derivative\n",
    "            rho = betai + xi.flatten().dot(residuals) / norms[i] #(norms[i] + 1e-3)\n",
    "            #soft threshold\n",
    "            beta[i] = np.sign(rho) * max(np.abs(rho) - lambda_reg * n / norms[i], 0.)#(norms[i] + 1e-3), 0.)\n",
    "            beta_changes[i] = np.abs(betai - beta[i])\n",
    "            if beta[i] != betai:\n",
    "                residuals += (betai - beta[i]) * xi\n",
    "        if max(beta_changes) < tol:\n",
    "            break\n",
    "    #print(it)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def erm(S: np.ndarray,\n",
    "        y_hat: np.ndarray,\n",
    "        y_insample: np.ndarray,\n",
    "        y_hat_insample: np.ndarray,\n",
    "        idx_bottom: np.ndarray,\n",
    "        method: str,\n",
    "        lambda_reg: float = 1e-3):\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    # y_hat_insample shape (n_hiers, obs)\n",
    "    # remove obs with nan values\n",
    "    nan_idx = np.isnan(y_hat_insample).any(axis=0)\n",
    "    y_insample = y_insample[:, ~nan_idx]\n",
    "    y_hat_insample = y_hat_insample[:, ~nan_idx]\n",
    "    #only using h validation steps to avoid \n",
    "    #computational burden\n",
    "    #print(y_hat.shape)\n",
    "    h = min(y_hat.shape[1], y_hat_insample.shape[1])\n",
    "    y_hat_insample = y_hat_insample[:, -h:] # shape (h, n_hiers)\n",
    "    y_insample = y_insample[:, -h:]\n",
    "    if method == 'closed':\n",
    "        B = np.linalg.inv(S.T @ S) @ S.T @ y_insample\n",
    "        B = B.T\n",
    "        P = np.linalg.pinv(y_hat_insample.T) @ B\n",
    "        P = P.T\n",
    "    elif method in ['reg', 'reg_bu']:\n",
    "        X = np.kron(np.array(S, order='F'), np.array(y_hat_insample.T, order='F'))\n",
    "        Pbu = np.zeros_like(S)\n",
    "        if method == 'reg_bu':\n",
    "            Pbu[idx_bottom] = S[idx_bottom]\n",
    "        Pbu = Pbu.T\n",
    "        Y = y_insample.T.flatten(order='F') - X @ Pbu.T.flatten(order='F')\n",
    "        if lambda_reg is None:\n",
    "            lambda_reg = np.max(np.abs(X.T.dot(Y)))\n",
    "        P = lasso(X, Y, lambda_reg)\n",
    "        P = P + Pbu.T.flatten(order='F')\n",
    "        P = P.reshape(-1, n_bottom, order='F').T\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "        \n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    \n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ERM:\n",
    "    \n",
    "    def __init__(self, method: str, lambda_reg: float = 1e-2):\n",
    "        self.method = method\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "    def reconcile(self, S: np.ndarray,\n",
    "                  y_hat: np.ndarray,\n",
    "                  y_insample: np.ndarray,\n",
    "                  y_hat_insample: np.ndarray,\n",
    "                  idx_bottom: np.ndarray):\n",
    "        return erm(S=S, y_hat=y_hat, \n",
    "                   y_insample=y_insample,\n",
    "                   y_hat_insample=y_hat_insample,\n",
    "                   idx_bottom=idx_bottom,\n",
    "                   method=self.method, lambda_reg=self.lambda_reg)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "for method in ['reg_bu']:\n",
    "    cls_erm = ERM(method=method, lambda_reg=None)\n",
    "    test_close(\n",
    "        cls_erm(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom,\n",
    "            y_insample=S @ y_bottom,\n",
    "            y_hat_insample=S @ y_hat_bottom_insample,\n",
    "            idx_bottom=idx_bottom\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
