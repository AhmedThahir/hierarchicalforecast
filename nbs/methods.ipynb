{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierachical Reconciliation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "from statsmodels.stats.moment_helpers import cov2corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import ExceptionExpected, test_close, test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reconcile(S: np.ndarray, P: np.ndarray, W: np.ndarray, \n",
    "               y_hat: np.ndarray, SP: np.ndarray = None):\n",
    "    if SP is None:\n",
    "        SP = S @ P\n",
    "    return np.matmul(SP, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bottom_up(S: np.ndarray,\n",
    "              y_hat: np.ndarray,\n",
    "              idx_bottom: List[int]):\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    P = np.zeros_like(S, dtype=np.float32)\n",
    "    P[idx_bottom] = S[idx_bottom]\n",
    "    P = P.T\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BottomUp:\n",
    "    \n",
    "    def reconcile(self,\n",
    "                  S: np.ndarray,\n",
    "                  y_hat: np.ndarray,\n",
    "                  idx_bottom: np.ndarray):\n",
    "        return bottom_up(S=S, y_hat=y_hat, idx_bottom=idx_bottom)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "S = np.array([\n",
    "    [1., 1., 1., 1.],\n",
    "    [1., 1., 0., 0.],\n",
    "    [0., 0., 1., 1.],\n",
    "    [0., 1., 0., 0.],\n",
    "    [1., 0., 0., 0.],\n",
    "    [0., 0., 1., 0.],\n",
    "    [0., 0., 0., 1.],\n",
    "])\n",
    "h = 10\n",
    "_y = np.array([10., 5., 4., 2., 1.])\n",
    "y_bottom = np.vstack([i * _y for i in range(1, 5)])\n",
    "resids_bottom = y_bottom - np.roll(y_bottom, 1)\n",
    "resids_bottom[:, 0] = np.nan\n",
    "y_hat_bottom = np.vstack([i * np.ones(h) for i in range(1, 5)])\n",
    "idx_bottom = [4, 3, 5, 6]\n",
    "levels = {'level1': np.array([0]),\n",
    "          'level2': np.array([1, 2]),\n",
    "          'level3': idx_bottom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "cls_bottom_up = BottomUp()\n",
    "test_eq(\n",
    "    cls_bottom_up(S=S, y_hat=S @ y_hat_bottom, idx_bottom=idx_bottom),\n",
    "    S @ y_hat_bottom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_strictly_hierarchical(S: np.ndarray, \n",
    "                             levels: Dict[str, np.ndarray]):\n",
    "    # main idea:\n",
    "    # if S represents a strictly hierarchical structure\n",
    "    # the number of paths before the bottom level\n",
    "    # should be equal to the number of nodes\n",
    "    # of the previuos level\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    # removing bottom level\n",
    "    levels_.popitem()\n",
    "    # making S categorical\n",
    "    hiers = [np.argmax(S[idx], axis=0) + 1 for _, idx in levels_.items()]\n",
    "    hiers = np.vstack(hiers)\n",
    "    paths = np.unique(hiers, axis=1).shape[1] \n",
    "    nodes = levels_.popitem()[1].size\n",
    "    return paths == nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert is_strictly_hierarchical(S, levels)\n",
    "S_non_hier = np.array([\n",
    "    [1., 1., 1., 1.], # total\n",
    "    [1., 1., 0., 0.], # city 1\n",
    "    [0., 0., 1., 1.], # city 2\n",
    "    [1., 0., 1., 0.], # transgender\n",
    "    [0., 1., 0., 1.], # no transgender\n",
    "    [1., 0., 0., 0.], #city 1 - transgender\n",
    "    [0., 1., 0., 0.], #city 1 - no transgender\n",
    "    [0., 0., 1., 0.], #city 2 - transgender\n",
    "    [0., 0., 0., 1.], #city 2 - no transgender\n",
    "])\n",
    "levels_non_hier = {\n",
    "    'Country': np.array([0]),\n",
    "    'Country/City': np.array([2, 1]),\n",
    "    'Country/Transgender': np.array([3, 4]),\n",
    "    'Country-City-Transgender': np.array([5, 6, 7, 8]),\n",
    "}\n",
    "assert not is_strictly_hierarchical(S_non_hier, levels_non_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_child_nodes(S: np.ndarray, levels: Dict[str, np.ndarray]):\n",
    "    childs = {}\n",
    "    level_names = list(levels.keys())\n",
    "    nodes = OrderedDict()\n",
    "    for i_level, level in enumerate(level_names[:-1]):\n",
    "        parent = levels[level]\n",
    "        child = np.zeros_like(S)\n",
    "        idx_child = levels[level_names[i_level+1]] \n",
    "        child[idx_child] = S[idx_child]\n",
    "        nodes_level = {}\n",
    "        for idx_parent_node in parent:\n",
    "            parent_node = S[idx_parent_node]\n",
    "            idx_node = child * parent_node.astype(bool)\n",
    "            idx_node, = np.where(idx_node.sum(axis=1) > 0)\n",
    "            nodes_level[idx_parent_node] = [idx for idx in idx_child if idx in idx_node]\n",
    "        nodes[level] = nodes_level\n",
    "    return nodes        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reconcile_fcst_proportions(S: np.ndarray, y_hat: np.ndarray,\n",
    "                                levels: Dict[str, np.ndarray],\n",
    "                                nodes: Dict[str, Dict[int, np.ndarray]],\n",
    "                                idx_top: int):\n",
    "    reconciled = np.zeros_like(y_hat)\n",
    "    reconciled[idx_top] = y_hat[idx_top]\n",
    "    level_names = list(levels.keys())\n",
    "    for i_level, level in enumerate(level_names[:-1]):\n",
    "        nodes_level = nodes[level]\n",
    "        for idx_parent, idx_childs in nodes_level.items():\n",
    "            fcst_parent = reconciled[idx_parent]\n",
    "            childs_sum = y_hat[idx_childs].sum()\n",
    "            for idx_child in idx_childs:\n",
    "                reconciled[idx_child] = y_hat[idx_child] * fcst_parent / childs_sum\n",
    "    return reconciled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def top_down(S: np.ndarray, \n",
    "             y_hat: np.ndarray,\n",
    "             y: np.ndarray,\n",
    "             levels: Dict[str, np.ndarray],\n",
    "             method: str):\n",
    "    if not is_strictly_hierarchical(S, levels):\n",
    "        raise ValueError('Top down reconciliation requires strictly hierarchical structures.')\n",
    "    \n",
    "    n_hiers, n_bottom = S.shape\n",
    "    idx_top = int(S.sum(axis=1).argmax())\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    idx_bottom = levels_[list(levels_)[-1]]\n",
    "    \n",
    "    if method == 'forecast_proportions':\n",
    "        nodes = _get_child_nodes(S=S, levels=levels)\n",
    "        reconciled = [_reconcile_fcst_proportions(S=S, y_hat=y_hat_[:, None], \n",
    "                                                  levels=levels_, \n",
    "                                                  nodes=nodes,\n",
    "                                                  idx_top=idx_top) \\\n",
    "                      for y_hat_ in y_hat.T]\n",
    "        reconciled = np.hstack(reconciled)\n",
    "        return reconciled\n",
    "    else:\n",
    "        y_top = y[idx_top]\n",
    "        y_btm = y[idx_bottom]\n",
    "        if method == 'average_proportions':\n",
    "            prop = np.mean(y_btm / y_top, axis=1)\n",
    "        elif method == 'proportion_averages':\n",
    "            prop = np.mean(y_btm, axis=1) / np.mean(y_top)\n",
    "        else:\n",
    "            raise Exception(f'Unknown method {method}')\n",
    "    P = np.zeros_like(S, np.float64).T #float 64 if prop is too small, happens with wiki2\n",
    "    P[:, idx_top] = prop\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TopDown:\n",
    "    \n",
    "    def __init__(self, method: str):\n",
    "        self.method = method\n",
    "    \n",
    "    def reconcile(self, \n",
    "                  S: np.ndarray, \n",
    "                  y_hat: np.ndarray,\n",
    "                  y: np.ndarray,\n",
    "                  levels: Dict[str, np.ndarray],):\n",
    "        return top_down(S=S, y_hat=y_hat, y=y, \n",
    "                        levels=levels,\n",
    "                        method=self.method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# we are able to recover forecasts \n",
    "# from top_down in this example\n",
    "# because the time series\n",
    "# share the same proportion\n",
    "# across time\n",
    "# but it is not a general case\n",
    "for method in ['forecast_proportions', 'average_proportions', 'proportion_averages']:\n",
    "    cls_top_down = TopDown(method=method)\n",
    "    test_close(\n",
    "        cls_top_down(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom, \n",
    "            y=S @ y_bottom, \n",
    "            levels=levels\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def middle_out(S: np.ndarray, \n",
    "               y_hat: np.ndarray,\n",
    "               y: np.ndarray,\n",
    "               levels: Dict[str, np.ndarray],\n",
    "               level: str,\n",
    "               top_down_method: str):\n",
    "    if not is_strictly_hierarchical(S, levels):\n",
    "        raise ValueError('Middle out reconciliation requires strictly hierarchical structures.')\n",
    "    if level not in levels.keys():\n",
    "        raise ValueError('You have to provide a `level` in `levels`.')\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    reconciled = np.full_like(y_hat, fill_value=np.nan)\n",
    "    cut_nodes = levels_[level]\n",
    "    # bottom up reconciliation\n",
    "    idxs_bu = []\n",
    "    for node, idx_node in levels_.items():\n",
    "        idxs_bu.append(idx_node)\n",
    "        if node == level:\n",
    "            break\n",
    "    idxs_bu = np.hstack(idxs_bu)\n",
    "    #bottom up forecasts\n",
    "    bu = bottom_up(S=np.unique(S[idxs_bu], axis=1), \n",
    "                   y_hat=y_hat[idxs_bu], \n",
    "                   idx_bottom=np.arange(len(idxs_bu))[-len(cut_nodes):])\n",
    "    reconciled[idxs_bu] = bu\n",
    "    \n",
    "    #top down\n",
    "    child_nodes = _get_child_nodes(S, levels_)\n",
    "    parents = {node: {level: np.array([node])} for node in cut_nodes}\n",
    "    level_names = list(levels.keys())\n",
    "    for lv, lv_child in zip(level_names[:-1], level_names[1:]):\n",
    "        for idx_parent, idxs_child in child_nodes[lv].items():\n",
    "            for idx_level_parent in parents.keys():\n",
    "                if any(idx_parent in val for val in parents[idx_level_parent].values()):\n",
    "                    parents[idx_level_parent][lv_child] = idxs_child\n",
    "    \n",
    "    for node, levels_node in parents.items():\n",
    "        idxs_node = np.hstack(list(levels_node.values()))\n",
    "        S_node = S[idxs_node]\n",
    "        S_node = S_node[:,~np.all(S_node == 0, axis=0)]\n",
    "        counter = 0\n",
    "        levels_node_ = deepcopy(levels_node)\n",
    "        for lv_name, idxs_level in levels_node_.items():\n",
    "            idxs_len = len(idxs_level)\n",
    "            levels_node_[lv_name] = np.arange(counter, idxs_len + counter)\n",
    "            counter += idxs_len\n",
    "        td = top_down(S_node, \n",
    "                      y_hat[idxs_node], \n",
    "                      y[idxs_node], \n",
    "                      levels_node_, \n",
    "                      method=top_down_method)\n",
    "        reconciled[idxs_node] = td\n",
    "    return reconciled\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MiddleOut:\n",
    "    \n",
    "    def __init__(self, level: str, top_down_method: str):\n",
    "        self.level = level\n",
    "        self.top_down_method = top_down_method\n",
    "    \n",
    "    def reconcile(self, \n",
    "                  S: np.ndarray, \n",
    "                  y_hat: np.ndarray,\n",
    "                  y: np.ndarray,\n",
    "                  levels: Dict[str, np.ndarray],):\n",
    "        return middle_out(S=S, y_hat=y_hat, y=y, \n",
    "                          levels=levels,\n",
    "                          level=self.level,\n",
    "                          top_down_method=self.top_down_method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# we are able to recover forecasts \n",
    "# from middle out in this example\n",
    "# because the time series\n",
    "# share the same proportion\n",
    "# across time\n",
    "# but it is not a general case\n",
    "for method in ['forecast_proportions', 'average_proportions', 'proportion_averages']:\n",
    "    cls_middle_out = MiddleOut(level='level2', top_down_method=method)\n",
    "    test_close(\n",
    "        cls_middle_out(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom, \n",
    "            y=S @ y_bottom, \n",
    "            levels=levels\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crossprod(x):\n",
    "    return x.T @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def min_trace(S: np.ndarray, \n",
    "              y_hat: np.ndarray,\n",
    "              residuals: np.ndarray,\n",
    "              method: str):\n",
    "    # shape residuals (obs, n_hiers)\n",
    "    res_methods = ['wls_var', 'mint_cov', 'mint_shrink']\n",
    "    if method in res_methods and residuals is None:\n",
    "        raise ValueError(f\"For methods {', '.join(res_methods)} you need to pass residuals\")\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    if method == 'ols':\n",
    "        W = np.eye(n_hiers)\n",
    "    elif method == 'wls_struct':\n",
    "        W = np.diag(S @ np.ones((n_bottom,)))\n",
    "    elif method in res_methods:\n",
    "        n, _ = residuals.shape\n",
    "        masked_res = np.ma.array(residuals, mask=np.isnan(residuals))\n",
    "        covm = np.ma.cov(masked_res, rowvar=False, allow_masked=True).data\n",
    "        if method == 'wls_var':\n",
    "            W = np.diag(np.diag(covm))\n",
    "        elif method == 'mint_cov':\n",
    "            W = covm\n",
    "        elif method == 'mint_shrink':\n",
    "            tar = np.diag(np.diag(covm))\n",
    "            corm = cov2corr(covm)\n",
    "            xs = np.divide(residuals, np.sqrt(np.diag(covm)))\n",
    "            xs = xs[~np.isnan(xs).any(axis=1), :]\n",
    "            v = (1 / (n * (n - 1))) * (crossprod(xs ** 2) - (1 / n) * (crossprod(xs) ** 2))\n",
    "            np.fill_diagonal(v, 0)\n",
    "            corapn = cov2corr(tar)\n",
    "            d = (corm - corapn) ** 2\n",
    "            lmd = v.sum() / d.sum()\n",
    "            lmd = max(min(lmd, 1), 0)\n",
    "            W = lmd * tar + (1 - lmd) * covm\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "    \n",
    "    eigenvalues, _ = np.linalg.eig(W)\n",
    "    if any(eigenvalues < 1e-8):\n",
    "        raise Exception(f'min_trace ({method}) needs covariance matrix to be positive definite.')\n",
    "        \n",
    "    R = S.T @ np.linalg.inv(W)\n",
    "    P = np.linalg.inv(R @ S) @ R\n",
    "    \n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MinTrace:\n",
    "    \n",
    "    def __init__(self, method: str):\n",
    "        self.method = method\n",
    "        \n",
    "    def reconcile(self, \n",
    "                  S: np.ndarray, \n",
    "                  y_hat: np.ndarray,\n",
    "                  residuals: np.ndarray):\n",
    "        return min_trace(S=S, y_hat=y_hat, \n",
    "                         residuals=residuals,\n",
    "                         method=self.method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "for method in ['ols', 'wls_struct', 'wls_var', 'mint_shrink']:\n",
    "    cls_min_trace = MinTrace(method=method)\n",
    "    test_close(\n",
    "        cls_min_trace(\n",
    "            S, \n",
    "            S @ y_hat_bottom, \n",
    "            np.transpose(S @ resids_bottom)\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )\n",
    "with ExceptionExpected(regex='min_trace (mint_cov)*'):\n",
    "    cls_min_trace = MinTrace(method='mint_cov')\n",
    "    cls_min_trace(\n",
    "        S, \n",
    "        S @ y_hat_bottom, \n",
    "        np.transpose(S @ resids_bottom)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def erm(S: np.ndarray,\n",
    "        y_hat: np.ndarray,\n",
    "        method: str,\n",
    "        lambda_reg: float = 1e-2):\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    if method == 'exact':\n",
    "        B = y_hat.T @ S @ np.linalg.inv(S.T @ S).T\n",
    "        P = B.T @ y_hat.T @ np.linalg.inv(y_hat @ y_hat.T + lambda_reg * np.eye(n_hiers))\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "        \n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    \n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ERM:\n",
    "    \n",
    "    def __init__(self, method: str, lambda_reg: float = 1e-2):\n",
    "        self.method = method\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "    def reconcile(self, S: np.ndarray,\n",
    "                  y_hat: np.ndarray):\n",
    "        return erm(S=S, y_hat=y_hat, \n",
    "                   method=self.method, lambda_reg=self.lambda_reg)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "for method in ['exact']:\n",
    "    cls_erm = ERM(method=method, lambda_reg=1e-3)\n",
    "    test_close(\n",
    "        cls_erm(\n",
    "            S, \n",
    "            S @ y_hat_bottom\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
